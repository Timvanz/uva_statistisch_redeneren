\documentclass[a4paper,12px]{article}
\usepackage{graphicx}
\usepackage[english]{babel}
\usepackage{fancyhdr}
\usepackage{lastpage}
\usepackage{xifthen}
\usepackage[linesnumberedhidden, titlenotnumbered]{algorithm2e}
\usepackage{lipsum}
\usepackage{hyperref}
\usepackage{array}
\usepackage{tabularx}
\usepackage{caption}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{placeins}
\usepackage{enumitem}

\usepackage{minted}
\usepackage{listings}
\usepackage{dsfont}
\usepackage{units}

\pagestyle{fancy}
\lhead{\includegraphics[width=7cm]{logoUvA}}
\rhead{\footnotesize \textsc {Report\\ \opdracht}}
\lfoot
{%
    \footnotesize \studentA
    \ifthenelse{\isundefined{\studentB}}{}{\\ \studentB}
    \ifthenelse{\isundefined{\studentC}}{}{\\ \studentC}
    \ifthenelse{\isundefined{\studentD}}{}{\\ \studentD}
    \ifthenelse{\isundefined{\studentE}}{}{\\ \studentE}
}
\cfoot{}
\rfoot{\small \textsc {Page \thepage\ of \pageref{LastPage}}}
\renewcommand{\footrulewidth}{0.5pt}

\fancypagestyle{firststyle}
{%
    \fancyhf{}
    \renewcommand{\headrulewidth}{0pt}
    \chead{\includegraphics[width=7cm]{logoUvA}}
    \rfoot{\small \textsc {Page \thepage\ of \pageref{LastPage}}}
}

\setlength{\topmargin}{-0.3in}
\setlength{\textheight}{630pt}
\setlength{\headsep}{40pt}
\setlength{\parindent}{0pt}

% =================================== DOC INFO ===================================

\newcommand{\opdracht}{Statistisch Redeneren}
\newcommand{\titel}{Lab 3}
\newcommand{\docent}{Rein van de Boomgaard}
\newcommand{\cursus}{Statistisch Redeneren}
\newcommand{\vakcode}{5062STRE6Y}
\newcommand{\datum}{\today}
\newcommand{\studentA}{Maico Timmerman}
\newcommand{\uvanetidA}{10542590}
\newcommand{\studentB}{Tim van Zalingen}
\newcommand{\uvanetidB}{10784012}
% \newcommand{\studentC}{Boudewijn Braams}
\newcommand{\uvanetidC}{10401040}
% \newcommand{\studentD}{Govert Verkes}
\newcommand{\uvanetidD}{10211748}
%\newcommand{\studentE}{Naam student 5}
\newcommand{\uvanetidE}{UvAnetID student 5}

% ===================================  ===================================

\begin{document}
\thispagestyle{firststyle}
\begin{center}
    \textsc{\Large \opdracht}\\[0.2cm]
    \rule{\linewidth}{0.5pt} \\[0.4cm]
    {\huge \bfseries \titel}
    \rule{\linewidth}{0.5pt} \\[0.2cm]
    {\large \datum  \\[0.4cm]}

    \begin{minipage}{0.4\textwidth}
        \begin{flushleft}

            \emph{Students:}\\
            {\studentA \\ {\small \uvanetidA \\[0.2cm]}}
            \ifthenelse{\isundefined{\studentB}}{}{\studentB \\ {\small \uvanetidB \\[0.2cm]}}
        \end{flushleft}
    \end{minipage}
    ~%
    \begin{minipage}{0.4\textwidth}
        \begin{flushright}
            \emph{Lecturer:} \\
            \docent \\[0.2cm]
            \emph{Course:} \\
            \cursus \\[0.2cm]
            % \emph{Student:}\\
            \ifthenelse{\isundefined{\studentC}}{}{\studentC \\ {\small \uvanetidC \\[0.2cm]}}
            \ifthenelse{\isundefined{\studentD}}{}{\studentD \\ {\small \uvanetidD \\[0.2cm]}}
            \ifthenelse{\isundefined{\studentE}}{}{\studentE \\ {\small \uvanetidE \\ [0.2cm]}}
        \end{flushright}
    \end{minipage}\\[1 cm]
\end{center}


% =================================== CONTENTS ===================================

\tableofcontents
\clearpage

% =================================== MAIN TEXT ===================================

\section{Lab Multivariate}
\subsection{19}
The expectation of \textbf{Z} is:
\begin{equation}
    \mu_z=\left( \begin{matrix}\mu_{x1}+\mu_{x2}\\\mu_{x1}-\mu_{x2}\end{matrix} \right)=
    \left(\begin{matrix}1-1\\1--1\end{matrix} \right)=
    \left(\begin{matrix}0\\2\end{matrix} \right)
\end{equation}
We can get \textbf{Z} by multiplying \textbf{X} in the following way:
\begin{equation}
    \label{eq:A_matrix}
    \text{\textbf{Z}}=\left(\begin{matrix}Z_1\\Z_2\end{matrix}\right)=
    \left(\begin{matrix}X_1+X_2\\X_1-X_2\end{matrix}\right)=
    \left(\begin{matrix}1&1\\1&-1\end{matrix}\right)\left(\begin{matrix}X_1\\X_2\end{matrix}\right)
\end{equation}
We can use this matrix that multiplies \textbf{X} to get \textbf{Z}, to get the
 covariance matrix:
\begin{equation}
    \Sigma_Z=\left(\begin{matrix}1&1\\1&-1\end{matrix}\right)
    \left(\begin{matrix}1&0\\0&4\end{matrix}\right)
    \left(\begin{matrix}1&1\\1&-1\end{matrix}\right)^T=
    \left(\begin{matrix}5&-3\\-3&5\end{matrix}\right)
\end{equation}
The covariance of $Z_1$ and $Z_2$ is not zero, so they are not independent.
\subsection{20}
First we calculate the covariance matrix for \textbf{Z}. We use the same matrix
 that multiplies \textbf{X} to get \textbf{Z} in equation \ref{eq:A_matrix}.
\begin{equation}
    \begin{aligned}
    \Sigma_Z&=\left(\begin{matrix}1&1\\1&-1\end{matrix}\right)
    \left(\begin{matrix}1&0\\0&c\end{matrix}\right)
    \left(\begin{matrix}1&1\\1&-1\end{matrix}\right)^T\\
    &=\left(\begin{matrix}1&1\\1&-1\end{matrix}\right)
    \left(\begin{matrix}1&1\\c&-c\end{matrix}\right)\\
    &=\left(\begin{matrix}1+c&1-c\\1-c&1+c\end{matrix}\right)
    \end{aligned}
\end{equation}
For the components of \textbf{Z} to be uncorrelated, the covariance of $Z_1$
 and $Z_2$ needs to be 0. This covariance is taken from $\Sigma_Z$.
\begin{equation}
    \begin{aligned}
    \text{cov}(Z_1, Z_2)=1-c&=0\\
    c&=1
    \end{aligned}
\end{equation}
\subsection{21}
The code for this exercise can be found in \textit{lab\_21.py}. Figure \ref{fig:21}
 shows the 12 scatter plots.
\begin{figure}
    \centering
    \includegraphics[width=1\textwidth]{fig21.png}
    \caption{12 scatter plots showing the non-diagonal elements from the data matrix}
    \label{fig:21}
\end{figure}
\FloatBarrier
\subsection{22}
Figure \ref{fig:22} shows us that for bigger N, de deviation in the covariance matrix
 and mean decrease. Which shows us that the accuracy of the estimators is dependent on N.
\begin{figure}
    \centering
    \includegraphics[width=1\textwidth]{fig22.png}
    \caption{}
    \label{fig:22}
\end{figure}
\FloatBarrier
When repeating the estimations for fixed N and collect the results in a data
 matrix, the covariance of this data matrix is the following:
\begin{equation}
\left(\begin{matrix}
  6.68374801 &   5.90243783 & -14.27310294 & -3.75627027\\
  5.90243783 &  11.73182492 & -20.63144665 &  1.7823714 \\
-14.27310294 & -20.63144665 &  49.69584792 & -8.45388543\\
 -3.75627027 &   1.7823714  &  -8.45388543 & 17.28203881\end{matrix}\right)
\end{equation}


\section{PCA}

\begin{equation}
\begin{aligned}
S &= \frac{1}{n-1} \sum\limits_{i=1}^{n} (\vec x_i - \vec m)(\vec x_i - \vec m)^T\\
  &= \frac{1}{n-1} \sum\limits_{i=1}^{n} (\vec x_i - \vec m)(\vec x_i^T - \vec m^T)\\
  &= \frac{1}{n-1} \sum\limits^n_{i=1} \left(\vec x_i \vec x_i^T - \vec x_i \vec m^T -
                                             \vec m \vec x_i^T + \vec m \vec m ^T\right) \\
\end{aligned}
\end{equation}
To ease the proof, we leave $\frac{1}{n-1}$ out of the equation.
\begin{equation}
\begin{aligned}
  &= \sum\limits^n_{i=1} \left(\vec x_i \vec x_i^T - \vec x_i \vec m^T - \vec m \vec
    x_i^T + \vec m \vec m^T\right)\\
  &= \sum\limits^n_{i=1} \vec x_i \vec x_i^T - \sum\limits^n_{i=1} \vec x_i \vec m^T - \sum\limits^n_{i=1} \vec m \vec
    x_i^T + \sum\limits^n_{i=1} \vec m \vec m^T \\
  &= \sum\limits^n_{i=1} \vec x_i \vec x_i^T - \left(\sum\limits^n_{i=1} \vec x_i\right)
    \vec m^T - \vec m \left(\sum\limits^n_{i=1} \vec x_i\right)^T + n \vec m \vec m^T\\
\end{aligned}
\end{equation}
It is know that $\vec nm = \sum\limits_{i=1}^n \vec x_i$.
\begin{equation}
\begin{aligned}
    &= \sum\limits^n_{i=1} \vec x_i \vec x_i^T - n \vec m \vec m^T - n \vec m \vec
    m^T + n \vec m \vec m^T \\
\end{aligned}
\end{equation}
By adding $\frac{1}{n-1}$ back into the equation, we come to the following result.
\begin{equation}
\begin{aligned}
    S &= \frac{\left(\sum\limits^n_{i=1} \vec x_i \vec x_i^T \right) - n \vec m \vec m^T}{n-1} \\
\end{aligned}
\end{equation}

In the final equation, the matrix that is created by $\sum\limits_{i=1}^n \vec
x_i \vec x_i^T$ and the vector $\vec m$ can be calculated without loading the
entire data matrix in memory.

%TODO More discussion?

% =================================== REFERENCES ===================================

%\clearpage
% \bibliographystyle{apalike}
% \bibliography{report}

\end{document}
